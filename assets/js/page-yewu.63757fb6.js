(window.webpackJsonp=window.webpackJsonp||[]).push([[117],{603:function(v,e,_){"use strict";_.r(e);var t=_(1),a=Object(t.a)({},(function(){var v=this,e=v.$createElement,_=v._self._c||e;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h2",{attrs:{id:"yewu"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#yewu"}},[v._v("#")]),v._v(" yewu")]),v._v(" "),_("h2",{attrs:{id:"正常的业务"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#正常的业务"}},[v._v("#")]),v._v(" 正常的业务")]),v._v(" "),_("p",[v._v("08.0 3 到 03.19北京新医保核心业务的开发，")]),v._v(" "),_("p",[v._v("负责业务模块")]),v._v(" "),_("p",[v._v("手工报销结算模块：")]),v._v(" "),_("p",[v._v("票据扫描，票据文件报盘导入，提供两定接口，院端自费信息上传接口，院端上传的自费信息进行预结算，结算；添加相应的规则校验；手工报销费用补支、追回及其审核发财务；")]),v._v(" "),_("p",[v._v("手工报销结算模块(医照人员)模块：单位报盘自费信息导入，数据审核，补支、追回及其审核模块；对明细进行分割，各个分笔的费用进行金额的分割；预结算，将个人信息，就诊的信息，明细信息调支付方式，得出最后可以结算信息，(报销的金额，各项医保基金支出的金额)，如统筹基金，大额基金，军残基金；")]),v._v(" "),_("p",[v._v("结算，将预结算算出的结算信息保存，同时保存参保人的待遇累计信息；")]),v._v(" "),_("p",[v._v("北京医保不同点")]),v._v(" "),_("p",[v._v("单位将单位参保人自费的信息进行汇总，通过报盘导入，")]),v._v(" "),_("p",[v._v("金额是单位将明细的金额进行分类，保存的是分类项金额，不是具体的明细金额")]),v._v(" "),_("p",[v._v("灵活就业，纯手工录入七大项金额；就诊，明细信息需要机构传入，然后，再经办模块直接结算；")]),v._v(" "),_("p",[v._v("模式增加了单位和机构的工作量；")]),v._v(" "),_("p",[v._v("校验规则比较多；")]),v._v(" "),_("p",[v._v("上传模块还可以进行批量结算，初审时，多次门诊交易可以结成一笔结算信息；")]),v._v(" "),_("h2",{attrs:{id:"还做了一个批量导出的功能"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#还做了一个批量导出的功能"}},[v._v("#")]),v._v(" 还做了一个批量导出的功能")]),v._v(" "),_("p",[v._v("项目前期给监管平台做的大数据批量导出的功能，前端查询模块查询业务数据，有导出功能，选择条件，将数据导出 excel 文件，每天业务量数据很大，每天都好几千万的数据。还要实现进度条的功能")]),v._v(" "),_("ol",[_("li",[v._v("使用 easyexcel 框架，分批次导出，50 万作为一个 excel 的导出文件，假如有 1000 万条数据，需要 for 循环 20 次，每次循环，去用 limit 分批次查询，当所有 excel 文件生成，将 20 个 excel 文件打包，给前端提供压缩文件的地址")]),v._v(" "),_("li",[v._v("使用流式查询，防止内存的溢出")]),v._v(" "),_("li",[v._v("使用 redis 保存该用户各个导出文件的进度，前端专门画了一个页面去查看用户所有导出事件文件生成的进度，"),_("code",[v._v("redis")]),v._v(" 结构使用 "),_("code",[v._v("hash")]),v._v(" 结构，key 使用用户的 id，"),_("code",[v._v("value")]),v._v(" 中的 "),_("code",[v._v("hash")]),v._v(" 的 "),_("code",[v._v("key")]),v._v("，导出文件的文件名，value 是导出文件的生成的进度，当压缩文件生成完，"),_("code",[v._v("value")]),v._v(" 为压缩文件的地址，前端使用定时器，不停的调查询接口，查询缓存中保存的进度")])]),v._v(" "),_("p",[v._v("用户正在导出的数据过多，可以添加限制次数，前端可以判断 value 值是文件地址时，显示可导出，导出按钮将文件下载。")]),v._v(" "),_("h2",{attrs:{id:"注"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#注"}},[v._v("#")]),v._v(" 注")]),v._v(" "),_("p",[v._v("每次向文件里面追加数据，类似与 "),_("code",[v._v("aof")])]),v._v(" "),_("p",[v._v("调用 "),_("code",[v._v("ArrayList.clear()")]),v._v("，或者把对象置空,使用 "),_("code",[v._v("JProfile")]),v._v(" 进行内存检测")]),v._v(" "),_("p",[v._v("通过 "),_("code",[v._v("JProfile")]),v._v(" 内存分析.最终问题定位完毕.")]),v._v(" "),_("p",[v._v("原因如下：100W 数据  生成一个文件的过程中，等文件生成完毕之后才能把数据库中的数据备份到历史表中，这个时候才能进行事务的提交，也就是执行 commit()， 并且删除原表数据，100W 数据按照 3000 一批写入文件，每批次只是通过 "),_("code",[v._v("PreparedStatement.addBatch()")]),v._v(";加入到批次里面去,并没有执行 "),_("code",[v._v("PreparedStatement.executeBatch()")]),v._v(",而是在 "),_("code",[v._v("commit()")]),v._v(" 之前统一调用的 "),_("code",[v._v("PreparedStatement.executeBatch()")]),v._v("，这样的话 "),_("code",[v._v("PreparedStatement")]),v._v(" 就会缓存 100W 条数据信息，造成了内存溢出.")]),v._v(" "),_("h2",{attrs:{id:"改进"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#改进"}},[v._v("#")]),v._v(" 改进")]),v._v(" "),_("p",[_("code",[v._v("Spring Batch")]),v._v(" 做批量。根据数据库的时间或者 ID 来进行批量处理后生成文件。然后将生成的文件放到某一个存储位置")]),v._v(" "),_("h2",{attrs:{id:"审核不通过-逻辑修改"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#审核不通过-逻辑修改"}},[v._v("#")]),v._v(" 审核不通过，逻辑修改")]),v._v(" "),_("p",[v._v("审核不通过时，对上传的信息做特殊处理，根据医院就诊 id，分组")])])}),[],!1,null,null,null);e.default=a.exports}}]);