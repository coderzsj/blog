(window.webpackJsonp=window.webpackJsonp||[]).push([[71],{587:function(s,a,t){"use strict";t.r(a);var n=t(1),e=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"hashmap的内部结构-线程不安全、基于jdk7"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap的内部结构-线程不安全、基于jdk7"}},[s._v("#")]),s._v(" HASHMAP的内部结构（线程不安全、基于JDK7）")]),s._v(" "),t("p",[s._v("hashmap是无序的，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。")]),s._v(" "),t("p",[s._v("HSAHMAP底层是基于数组和链表实现的，两个重要的参数：容量和负载因子；容量的默认大小的16，负载因子是0.75，当HashMap的size>16*0.75时就会发生扩容（容量和负载因子都可以自由调整）。")]),s._v(" "),t("p",[s._v("内部包含了一个ENTRY类型的数组TABLE。")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("transient")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" table"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        value "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" v"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" k"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        hash "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" newValue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),s._v(" oldValue "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        value "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newValue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" oldValue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("boolean")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" o"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("o "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),s._v(" e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Entry")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" o"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" k1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" k2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("k1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" k2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("k1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" k1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("k2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" v1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" v2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("v1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" v2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("v1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" v1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("equals")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("v2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Objects")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Objects")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("toString")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"="')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getValue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br")])]),t("h2",{attrs:{id:"hashmap-特性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap-特性"}},[s._v("#")]),s._v(" HashMap 特性")]),s._v(" "),t("ol",[t("li",[s._v("存储键值对实现快速存取，允许为null。key值不可重复，若key值重复则覆盖。")]),s._v(" "),t("li",[s._v("非同步，线程不安全。")]),s._v(" "),t("li",[s._v("底层是hash表，不保证有序(比如插入的顺序，自然顺序)")])]),s._v(" "),t("p",[s._v("Treemap默认按照key的字典顺序来排序(升序) ，也可以自定义排序规则:要实现Comparator接口。")]),s._v(" "),t("p",[s._v("ArrayList，linkedList插入和检索顺序是一样的。")]),s._v(" "),t("p",[s._v("LinkedHashMap实现顺序性")]),s._v(" "),t("h2",{attrs:{id:"hashmap的底层原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap的底层原理"}},[s._v("#")]),s._v(" HashMap的底层原理")]),s._v(" "),t("p",[s._v("基于hashing的原理，jdk8后采用数组+链表+红黑树的数据结构。")]),s._v(" "),t("p",[s._v("我们通过put和get存储和获取对象。")]),s._v(" "),t("p",[s._v("当我们给put()方法传递键和值时，先对键做一个hashCode()的计算来得到它在bucket数组中的位置来存储Entry对象。")]),s._v(" "),t("p",[s._v("当获取对象时，通过get获取到bucket的位置，再通过键对象的equals()方法找到正确的键值对，然后在返回值对象。")]),s._v(" "),t("h2",{attrs:{id:"put方法实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#put方法实现"}},[s._v("#")]),s._v(" put方法实现")]),s._v(" "),t("ol",[t("li",[s._v("计算关于key的hashcode值（与Key.hashCode的高16位做异或运算）")]),s._v(" "),t("li",[s._v("如果散列表为空时，调用resize()初始化散列表")]),s._v(" "),t("li",[s._v("如果没有发生碰撞，直接添加元素到散列表中去")]),s._v(" "),t("li",[s._v("如果发生了碰撞(hashCode值相同)，进行三种判断\n"),t("ul",[t("li",[s._v("若key地址相同或者equals后内容相同，则替换旧值")]),s._v(" "),t("li",[s._v("如果是红黑树结构，就调用树的插入方法")]),s._v(" "),t("li",[s._v("链表结构，循环遍历直到链表中某个节点为空，尾插法进行插入，插入之后判断链表个数是否到达变成红黑树的阙值8；也可以遍历到有节点与插入元素的哈希值和内容相同，进行覆盖。")])])])]),s._v(" "),t("h3",{attrs:{id:"扩容机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩容机制"}},[s._v("#")]),s._v(" 扩容机制")]),s._v(" "),t("p",[s._v("如果桶满了大于阀值，则resize进行扩容")]),s._v(" "),t("ol",[t("li",[s._v("初始化数组table")]),s._v(" "),t("li",[s._v("当数组table的size达到阙值时即++size > load factor * capacity 时，也是在putVal函数中")])]),s._v(" "),t("p",[s._v("扩容需要重新分配一个新数组，新数组是老数组的2倍长，然后遍历整个老结构，把所有的元素挨个重新hash分配到新结构中去。")]),s._v(" "),t("div",{staticClass:"custom-block info"},[t("p",{staticClass:"custom-block-title"},[s._v("ps")]),s._v(" "),t("p",[s._v("可见底层数据结构用到了数组，到最后会因为容量问题都需要进行扩容操作")])]),s._v(" "),t("h2",{attrs:{id:"get方法实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#get方法实现"}},[s._v("#")]),s._v(" get方法实现")]),s._v(" "),t("p",[s._v("对key的hashCode进行hashing，与运算计算下标获取bucket位置，如果在桶的首位上就可以找到就直接返回，否则在树中找或者链表中遍历找。")]),s._v(" "),t("p",[s._v("如果有hash冲突，则利用equals方法去遍历链表查找节点。")]),s._v(" "),t("h2",{attrs:{id:"hash方法实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hash方法实现"}},[s._v("#")]),s._v(" hash方法实现")]),s._v(" "),t("p",[s._v("对key的hashCode做hash操作，与高16位做异或运算")]),s._v(" "),t("p",[s._v("还有平方取中法，除留余数法，伪随机数法")]),s._v(" "),t("h3",{attrs:{id:"异或运算原因"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#异或运算原因"}},[s._v("#")]),s._v(" 异或运算原因")]),s._v(" "),t("p",[s._v("为什么不直接将key作为哈希值而是与高16位做异或运算？")]),s._v(" "),t("p",[s._v("因为数组位置的确定用的是与运算，仅仅最后四位有效，设计者将key的哈希值与高16为做异或运算使得在做&运算确定数组的插入位置时，此时的低位实际是高位与低位的结合，增加了随机性，减少了哈希碰撞的次数。")]),s._v(" "),t("p",[s._v("HashMap默认初始化长度为16，并且每次自动扩展或者是手动初始化容量时，必须是2的幂。")]),s._v(" "),t("h3",{attrs:{id:"_2次幂原因"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2次幂原因"}},[s._v("#")]),s._v(" 2次幂原因")]),s._v(" "),t("p",[s._v("为什么是16？为什么必须是2的幂？如果输入值不是2的幂比如10会怎么样？")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("为了数据的均匀分布，减少哈希碰撞。因为确定数组位置是用的位运算，若数据不是2的次幂则会增加哈希碰撞的次数和浪费数组空间。(PS:其实若不考虑效率，求余也可以就不用位运算了也不用长度必需为2的幂次) "),t("code",[s._v("hash % length 等于 hash & ( length - 1)")])])]),s._v(" "),t("li",[t("p",[s._v("输入数据若不是2的幂，HashMap通过一通位移运算和或运算得到的肯定是2的幂次数，并且是离那个数最近的数字,")])])]),s._v(" "),t("p",[s._v("按位与运算规则:相同的二进制数位上,都是1的时候,结果为1.否则为0;")]),s._v(" "),t("h3",{attrs:{id:"解决hash冲突"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#解决hash冲突"}},[s._v("#")]),s._v(" 解决hash冲突")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("static")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hash")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" h"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("h "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("h "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("p",[s._v("key 的 hashCode 赋值给 h，然后与 h 无符号右移 16 位后的二进制进行按位异或得到最后的 hash 值。")]),s._v(" "),t("p",[s._v("会产生哈希碰撞，若key值相同则替换旧值，不然链接到链表后面，链表长度超过阙值8就转为红黑树存储")]),s._v(" "),t("p",[s._v("HashCode相同，通过equals比较内容获取值对象")]),s._v(" "),t("h3",{attrs:{id:"扩容"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩容"}},[s._v("#")]),s._v(" 扩容")]),s._v(" "),t("p",[s._v("如果HashMap的大小超过了负载因子(load factor)定义的容量")]),s._v(" "),t("p",[s._v("超过阙值会进行扩容操作，概括的讲就是扩容后的数组大小是原数组的2倍，将原来的元素 rehash 放入到新的散列表中去。")]),s._v(" "),t("p",[s._v("扩容这个过程涉及到 rehash、复制数据等操作，非常消耗性能。所以开发中尽量减少扩容的次数，可以通过创建 HashMap 集合对象时指定初始容量来尽量避免。")]),s._v(" "),t("h3",{attrs:{id:"rehash方法-不需要重新计算hash"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rehash方法-不需要重新计算hash"}},[s._v("#")]),s._v(" rehash方法：不需要重新计算hash")]),s._v(" "),t("p",[s._v("因为每次扩容都是翻倍，扩容之后结点要么就在原来的位置，与原来计算的 (n - 1) & hash 的结果相比，只是多了一个 bit 位，rehash设计为结点要么就在原来的位置，要么就被分配到 "),t("strong",[s._v("“原位置 + 旧容量”")]),s._v(" 这个位置。")]),s._v(" "),t("p",[s._v("元素桶位置，新增的 1bit 是0还是 1是随机的，在 resize 的过程中保证了 rehash 之后每个桶上的结点数一定小于等于原来桶上的结点数，保证了rehash之后不会出现更严重的 hash 冲突，均匀的把之前的冲突的结点分散到新的桶中了。")]),s._v(" "),t("h2",{attrs:{id:"hashtable"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashtable"}},[s._v("#")]),s._v(" hashtable")]),s._v(" "),t("p",[s._v("Hashtable没有自定义哈希算法，而直接采用的key的hashCode()。")]),s._v(" "),t("h2",{attrs:{id:"loadfactor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#loadfactor"}},[s._v("#")]),s._v(" loadFactor")]),s._v(" "),t("p",[s._v("loadFactor表示HashMap的拥挤程度，影响hash操作到同一个数组位置的概率。")]),s._v(" "),t("p",[s._v("默认loadFactor等于0.75，当HashMap里面容纳的元素已经达到HashMap数组长度的75%时，表示HashMap太挤了，需要扩容，在HashMap的构造器中可以定制loadFactor。")]),s._v(" "),t("h2",{attrs:{id:"红黑树"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#红黑树"}},[s._v("#")]),s._v(" 红黑树")]),s._v(" "),t("h3",{attrs:{id:"二叉查找树"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二叉查找树"}},[s._v("#")]),s._v(" 二叉查找树")]),s._v(" "),t("p",[s._v("二叉查找树就是左结点小于根节点，右结点大于根节点的一种排序树，也叫二叉搜索树。也叫BST，英文Binary Sort Tree。")]),s._v(" "),t("p",[s._v("二叉查找树比普通树查找更快，查找、插入、删除的时间复杂度为"),t("code",[s._v("O（logN）")]),s._v("。但是二叉查找树有一种极端的情况，就是会变成一种线性链表似的结构。此时时间复杂度就变成了"),t("code",[s._v("O（N）")]),s._v("，为了解决这种情况，出现了二叉平衡树。")]),s._v(" "),t("h3",{attrs:{id:"avl"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#avl"}},[s._v("#")]),s._v(" avl")]),s._v(" "),t("p",[s._v("平衡二叉树全称平衡二叉搜索树，也叫AVL树。是一种自平衡的树。")]),s._v(" "),t("p",[s._v("AVL树也规定了左结点小于根节点，右结点大于根节点。并且还规定了左子树和右子树的高度差不得超过1。")]),s._v(" "),t("p",[s._v("这样保证了它不会成为线性的链表。")]),s._v(" "),t("p",[s._v("AVL树的查找稳定，查找、插入、删除的时间复杂度都为O（logN），但是由于要维持自身的平衡，所以进行插入和删除结点操作的时候，需要对结点进行频繁的旋转。")]),s._v(" "),t("h3",{attrs:{id:"redblack树"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redblack树"}},[s._v("#")]),s._v(" RedBlack树")]),s._v(" "),t("p",[s._v("红黑树的使用场景\njava中使用到红黑树的有TreeSet和JDK1.8的HashMap。")]),s._v(" "),t("p",[s._v("红黑树也叫RB树，RB-Tree。是一种自平衡的二叉查找树，它的节点的颜色为红色和黑色。它不严格控制左、右子树高度或节点数之差小于等于1。也是一种解决二叉查找树极端情况的数据结构。")]),s._v(" "),t("p",[s._v("当链表长度大于8时，遍历查找效率较慢，故引入红黑树;因为红黑树在插入新数据之后，可能会通过左旋、右旋、变色来保持平衡，故链路较短时，不适合用红黑树。")]),s._v(" "),t("p",[s._v("红黑树的特性：")]),s._v(" "),t("ol",[t("li",[s._v("节点是红色或黑色。")]),s._v(" "),t("li",[s._v("根节点是黑色。")]),s._v(" "),t("li",[s._v("每个叶子节点都是黑色的空节点（NIL节点）。")]),s._v(" "),t("li",[s._v("每个红色节点的两个子节点都是黑色。也就是说从每个叶子到根的所有路径上不能有两个连续的红色节点)。")]),s._v(" "),t("li",[s._v("从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。")])]),s._v(" "),t("p",[s._v("旋转的目的是将节点多的一支出让节点给另一个节点少的一支，旋转操作在插入和删除操作中经常会用到，所以要熟记。")]),s._v(" "),t("p",[s._v("它们非常相似，真正的区别在于在任何添加/删除操作时完成的旋转操作次数。保证平衡性的最大目的就是降低术的高度，因为树的查找性能取决于树的高度，所以树的高度越低搜索的效率越高！")]),s._v(" "),t("p",[s._v("这也是为什么存在二叉树、搜索二叉树等，各类树的目的。")]),s._v(" "),t("p",[s._v("红黑树在查找方面和AVL树操作几乎相同。 但是在插入和删除操作上，AVL树每次插入删除会进行大量的平衡度计算，红黑树没有像avl严格的高度平衡，它只要求部分地达到平衡要求，结合变色，降低了对旋转的要求，从而提高了性能。")]),s._v(" "),t("p",[s._v("红黑树能够以"),t("code",[s._v("O(log^2n)")]),s._v("的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。")]),s._v(" "),t("h2",{attrs:{id:"平时在使用hashmap时一般使用什么类型的元素作为key"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#平时在使用hashmap时一般使用什么类型的元素作为key"}},[s._v("#")]),s._v(" 平时在使用HashMap时一般使用什么类型的元素作为Key？")]),s._v(" "),t("p",[s._v("选择"),t("code",[s._v("Integer")]),s._v("，"),t("code",[s._v("String")]),s._v("这种不可变的类型，像对"),t("code",[s._v("String")]),s._v("的一切操作都是新建一个"),t("code",[s._v("String")]),s._v("对象，对新的对象进行拼接分割等，这些类已经很规范的覆写了"),t("code",[s._v("hashCode()")]),s._v("以及"),t("code",[s._v("equals()")]),s._v("方法。作为不可变类天生是线程安全的，")]),s._v(" "),t("h2",{attrs:{id:"hashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap"}},[s._v("#")]),s._v(" HashMap")]),s._v(" "),t("p",[s._v("JDK1.7版本，HashMap的数据结构是什么？")]),s._v(" "),t("p",[s._v("数组+单向链表")]),s._v(" "),t("p",[s._v("什么叫做Hash桶")]),s._v(" "),t("p",[s._v("数组中的单向链表")]),s._v(" "),t("p",[s._v("HashMap的数组长度为什么必须是2的幂？")]),s._v(" "),t("p",[s._v("计算元素存在数组中下标的算法：hash值 & 数组长度-1")]),s._v(" "),t("p",[s._v("如果数组长度不是2的幂，减1后二进制的某一位有可能出现0，导致数组某个位置永远存不到数据")]),s._v(" "),t("p",[s._v("HashMap的默认负载因子是多少，作用是什么？")]),s._v(" "),t("p",[s._v("默认负载因子是0.75")]),s._v(" "),t("p",[s._v("作用：数组长度*负载因子=阈值（扩容条件）")]),s._v(" "),t("p",[s._v("HashMap的默认负载因子为什么是0.75？")]),s._v(" "),t("p",[s._v("取得了时间和空间的平衡")]),s._v(" "),t("p",[s._v("假设负载因子过大，导致数组装满后才扩容，牺牲时间，利用空间")]),s._v(" "),t("p",[s._v("假设负载因子过小，导致数组装载较少内容就扩容，牺牲空间，利用时间")]),s._v(" "),t("p",[s._v("HashMax数组最大长度是多少？")]),s._v(" "),t("p",[s._v("1 << 30")]),s._v(" "),t("p",[s._v("HashMap数组最大长度为什么是1 << 30？")]),s._v(" "),t("p",[s._v("因为数组长度必须是2的幂并且HashMap数组最大长度的变量为int类型，所有1<<30")]),s._v(" "),t("p",[s._v("什么叫做Hash碰撞/冲突？")]),s._v(" "),t("p",[s._v("两个对象的hash值一样，导致在数组中的下标一样")]),s._v(" "),t("p",[s._v("HashMap何时扩容？")]),s._v(" "),t("p",[s._v("元素个数>=阈值，并且存入数据的位置不等于null")]),s._v(" "),t("h2",{attrs:{id:"hashmap扩容机制是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap扩容机制是什么"}},[s._v("#")]),s._v(" HashMap扩容机制是什么？")]),s._v(" "),t("ol",[t("li",[s._v("如果节点的NEXT属性为NULL，则说明这个一个最正常的节点，不是桶内链表，也不是红黑树，这样的节点可以直接计算索引位置，然后插入。")]),s._v(" "),t("li",[s._v("如果是一颗红黑树，会使用SPLIT方法进行处理，原理就是将红黑树拆分成两个TREENODE链表，然后判断每个链表的长度是否小于等于六，如果是，九江TREENODE转换成桶内链表，否则再转换成红黑树。")]),s._v(" "),t("li",[s._v("如果是桶内链表，则将链表拷贝到新数组中，保证链表的顺序不变。")])]),s._v(" "),t("p",[s._v("原来的2倍，在REHASH之后，元素的存放位置要么是在原位置，要么是在原位置的基础上向下移动之前容量个数的位置。比如：上次容量是16，下次扩容后容量变成了16*2=32。如果一个元素原先在下表为七的位置上，那么扩容后，该元素要么还在七的位置上，要么就在七加十六的位置上。")]),s._v(" "),t("p",[s._v("HashMap存入null键的位置？")]),s._v(" "),t("p",[s._v("hash数组下标为0的位置")]),s._v(" "),t("p",[s._v("什么叫做Hash回环？")]),s._v(" "),t("p",[s._v("多线程下会出现Hash回环")]),s._v(" "),t("p",[s._v("线程1：不断添加数据，导致不断扩容")]),s._v(" "),t("p",[s._v("线程2：不断遍历")]),s._v(" "),t("p",[s._v("出现Hash回环，活该，HashMap明确说明该集合不是个线程安全的集合，多线程下应该使用ConcurrentHashMap")]),s._v(" "),t("p",[s._v("JDK1.7版本和JDK1.8版本的HashMap的区别")]),s._v(" "),t("p",[s._v("JDK1.7：数组+链表，头插法，通过散列算法获取hash值")]),s._v(" "),t("p",[s._v("JDK1.8：数组+链表+红黑树，尾插法，通过低16位^高16位让hash值更加散列")]),s._v(" "),t("p",[s._v("JDK1.8版本HashMap为什么添加红黑树的数据结构？")]),s._v(" "),t("p",[s._v("因为链表查询慢，红黑树查询快")]),s._v(" "),t("p",[s._v("JDK1.8版本什么时候由数组+链表变成数组+红黑树")]),s._v(" "),t("p",[s._v("链表长度>8并且数组长度>64时，从数组+链表变成数组+红黑树")]),s._v(" "),t("p",[s._v("JDK1.8版本为什么链表长度大于8时，变成数组+红黑树")]),s._v(" "),t("p",[s._v("因为泊松部分（统计概率学），当红黑树里的数据小于6\n时，又会将数组+红黑树变会数组+链表；而且根据统计，链表中节点数是8的概率已经接近千分之一，而且此时链表的性能已经很差了。")])])}),[],!1,null,null,null);a.default=e.exports}}]);